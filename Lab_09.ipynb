{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0],[0,1],[1,0],[1,1]], dtype = np.float32)\n",
    "y_data = np.array([[0],[1],[1],[0]], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.702462 [[-0.0739796 ]\n",
      " [ 0.49104735]]\n",
      "100 0.695309 [[-0.04573989]\n",
      " [ 0.2568911 ]]\n",
      "200 0.69389 [[-0.01022104]\n",
      " [ 0.15156569]]\n",
      "300 0.693416 [[ 0.00447703]\n",
      " [ 0.09092419]]\n",
      "400 0.69325 [[ 0.00910666]\n",
      " [ 0.05529081]]\n",
      "500 0.693188 [[ 0.00939742]\n",
      " [ 0.03407009]]\n",
      "600 0.693164 [[ 0.00807946]\n",
      " [ 0.02125999]]\n",
      "700 0.693155 [[ 0.00638099]\n",
      " [ 0.01342222]]\n",
      "800 0.69315 [[ 0.00480249]\n",
      " [ 0.00856401]]\n",
      "900 0.693149 [[ 0.00350624]\n",
      " [ 0.00551569]]\n",
      "1000 0.693148 [[ 0.00250802]\n",
      " [ 0.00358148]]\n",
      "1100 0.693147 [[ 0.00176837]\n",
      " [ 0.00234184]]\n",
      "1200 0.693147 [[ 0.00123396]\n",
      " [ 0.0015403 ]]\n",
      "1300 0.693147 [[ 0.00085447]\n",
      " [ 0.00101812]]\n",
      "1400 0.693147 [[ 0.00058824]\n",
      " [ 0.00067564]]\n",
      "1500 0.693147 [[ 0.00040325]\n",
      " [ 0.00044995]]\n",
      "1600 0.693147 [[ 0.00027545]\n",
      " [ 0.0003004 ]]\n",
      "1700 0.693147 [[ 0.00018767]\n",
      " [ 0.000201  ]]\n",
      "1800 0.693147 [[ 0.0001276 ]\n",
      " [ 0.00013472]]\n",
      "1900 0.693147 [[  8.66178525e-05]\n",
      " [  9.04211120e-05]]\n",
      "2000 0.693147 [[  5.87288414e-05]\n",
      " [  6.07588554e-05]]\n",
      "2100 0.693147 [[  3.97775439e-05]\n",
      " [  4.08628293e-05]]\n",
      "2200 0.693147 [[  2.69208158e-05]\n",
      " [  2.74935082e-05]]\n",
      "2300 0.693147 [[  1.82081021e-05]\n",
      " [  1.85110857e-05]]\n",
      "2400 0.693147 [[  1.22998017e-05]\n",
      " [  1.24716489e-05]]\n",
      "2500 0.693147 [[  8.31522811e-06]\n",
      " [  8.39022050e-06]]\n",
      "2600 0.693147 [[  5.60917806e-06]\n",
      " [  5.64542916e-06]]\n",
      "2700 0.693147 [[  3.79570429e-06]\n",
      " [  3.81705331e-06]]\n",
      "2800 0.693147 [[  2.54698989e-06]\n",
      " [  2.55343707e-06]]\n",
      "2900 0.693147 [[  1.74083357e-06]\n",
      " [  1.74132038e-06]]\n",
      "3000 0.693147 [[  1.16862634e-06]\n",
      " [  1.16911315e-06]]\n",
      "3100 0.693147 [[  7.79704123e-07]\n",
      " [  7.80190931e-07]]\n",
      "3200 0.693147 [[  4.99561793e-07]\n",
      " [  5.00048600e-07]]\n",
      "3300 0.693147 [[  3.50550039e-07]\n",
      " [  3.51036846e-07]]\n",
      "3400 0.693147 [[  2.19419320e-07]\n",
      " [  2.19906127e-07]]\n",
      "3500 0.693147 [[  1.56834204e-07]\n",
      " [  1.57321011e-07]]\n",
      "3600 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "3700 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "3800 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "3900 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "4000 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "4100 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "4200 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "4300 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "4400 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "4500 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "4600 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "4700 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "4800 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "4900 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "5000 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "5100 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "5200 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "5300 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "5400 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "5500 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "5600 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "5700 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "5800 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "5900 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "6000 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "6100 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "6200 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "6300 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "6400 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "6500 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "6600 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "6700 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "6800 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "6900 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "7000 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "7100 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "7200 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "7300 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "7400 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "7500 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "7600 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "7700 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "7800 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "7900 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "8000 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "8100 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "8200 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "8300 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "8400 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "8500 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "8600 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "8700 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "8800 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "8900 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "9000 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "9100 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "9200 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "9300 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "9400 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "9500 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "9600 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "9700 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "9800 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "9900 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "10000 0.693147 [[  1.32992255e-07]\n",
      " [  1.33479062e-07]]\n",
      "\n",
      "Hypothesis:  [[ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]] \n",
      "Correct:  [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]] \n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR with NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.735208 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "100 0.689646 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "200 0.687788 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "300 0.685827 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "400 0.683532 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "500 0.680754 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "600 0.677328 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "700 0.67306 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "800 0.667727 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "900 0.661072 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "1000 0.652841 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "1100 0.642824 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "1200 0.630943 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "1300 0.61732 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "1400 0.602301 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "1500 0.586397 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "1600 0.570162 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "1700 0.554086 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "1800 0.538533 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "1900 0.523733 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "2000 0.509814 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "2100 0.496834 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "2200 0.484813 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "2300 0.473747 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "2400 0.463614 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "2500 0.454379 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "2600 0.445997 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "2700 0.438412 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "2800 0.431563 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "2900 0.425388 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "3000 0.419824 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "3100 0.414808 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "3200 0.410285 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "3300 0.4062 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "3400 0.402506 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "3500 0.399159 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "3600 0.39612 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "3700 0.393356 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "3800 0.390835 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "3900 0.388531 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "4000 0.386421 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "4100 0.384484 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "4200 0.382701 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "4300 0.381058 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "4400 0.379539 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "4500 0.378133 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "4600 0.376828 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "4700 0.375614 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "4800 0.374484 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "4900 0.37343 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "5000 0.372444 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "5100 0.371521 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "5200 0.370655 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "5300 0.369842 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "5400 0.369076 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "5500 0.368356 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "5600 0.367676 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "5700 0.367033 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "5800 0.366425 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "5900 0.36585 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "6000 0.365304 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "6100 0.364786 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "6200 0.364293 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "6300 0.363825 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "6400 0.363379 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "6500 0.362954 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "6600 0.362548 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "6700 0.36216 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "6800 0.361789 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "6900 0.361435 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "7000 0.361096 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "7100 0.36077 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "7200 0.360458 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "7300 0.360159 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "7400 0.359871 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "7500 0.359595 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "7600 0.359329 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "7700 0.359073 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "7800 0.358827 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "7900 0.358589 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "8000 0.35836 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "8100 0.358139 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "8200 0.357926 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "8300 0.35772 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "8400 0.357521 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "8500 0.357329 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "8600 0.357143 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "8700 0.356962 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "8800 0.356788 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "8900 0.356619 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "9000 0.356455 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "9100 0.356296 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "9200 0.356142 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "9300 0.355993 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "9400 0.355848 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "9500 0.355707 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "9600 0.35557 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "9700 0.355437 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "9800 0.355308 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "9900 0.355182 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "10000 0.355059 [[ 0.59710479]\n",
      " [-0.28236789]]\n",
      "\n",
      "Hypothesis:  [[ 0.00778516]\n",
      " [ 0.9884764 ]\n",
      " [ 0.49827179]\n",
      " [ 0.50550669]] \n",
      "Correct:  [[ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]] \n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.22309 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "100 0.692026 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "200 0.67866 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "300 0.669986 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "400 0.661474 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "500 0.652187 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "600 0.641643 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "700 0.629659 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "800 0.616278 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "900 0.601733 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "1000 0.586393 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "1100 0.570689 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "1200 0.55503 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "1300 0.539724 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "1400 0.524932 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "1500 0.510653 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "1600 0.496707 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "1700 0.482691 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "1800 0.467859 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "1900 0.450918 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "2000 0.429875 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "2100 0.402712 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "2200 0.369586 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "2300 0.333734 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "2400 0.298776 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "2500 0.266651 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "2600 0.237941 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "2700 0.212647 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "2800 0.190568 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "2900 0.171417 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "3000 0.154861 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "3100 0.140561 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "3200 0.128193 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "3300 0.117468 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "3400 0.108131 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "3500 0.0999665 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "3600 0.0927939 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "3700 0.0864621 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "3800 0.0808455 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "3900 0.0758399 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "4000 0.0713586 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "4100 0.0673293 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "4200 0.0636915 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "4300 0.0603944 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "4400 0.0573951 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "4500 0.0546572 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "4600 0.0521497 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "4700 0.0498462 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "4800 0.0477239 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "4900 0.0457632 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "5000 0.0439471 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "5100 0.0422609 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "5200 0.0406917 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "5300 0.0392281 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "5400 0.0378603 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "5500 0.0365794 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "5600 0.0353777 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "5700 0.0342485 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "5800 0.0331854 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "5900 0.0321831 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "6000 0.0312366 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "6100 0.0303415 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "6200 0.0294939 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "6300 0.0286902 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "6400 0.0279272 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "6500 0.0272019 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "6600 0.0265118 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "6700 0.0258543 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "6800 0.0252273 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "6900 0.0246287 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "7000 0.0240568 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "7100 0.0235097 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "7200 0.022986 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "7300 0.0224842 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "7400 0.0220031 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "7500 0.0215413 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "7600 0.0210978 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "7700 0.0206715 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "7800 0.0202615 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "7900 0.0198669 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "8000 0.0194868 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "8100 0.0191205 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "8200 0.0187673 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "8300 0.0184264 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "8400 0.0180972 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "8500 0.0177793 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "8600 0.0174719 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "8700 0.0171747 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "8800 0.0168871 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "8900 0.0166086 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "9000 0.016339 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "9100 0.0160776 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "9200 0.0158243 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "9300 0.0155785 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "9400 0.0153401 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "9500 0.0151086 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "9600 0.0148838 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "9700 0.0146654 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "9800 0.0144531 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "9900 0.0142467 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "10000 0.014046 [[-0.97372705]\n",
      " [ 0.94198668]]\n",
      "\n",
      "Hypothesis:  [[ 0.62064195]\n",
      " [ 0.71715468]\n",
      " [ 0.66718704]\n",
      " [ 0.74036002]] \n",
      "Correct:  [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10, 10]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([10, 10]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([10]), name='bias3')\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([10, 1]), name='weight4')\n",
    "b4 = tf.Variable(tf.random_normal([1]), name='bias4')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer3, W4) + b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.811265 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "100 0.688587 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "200 0.687315 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "300 0.686227 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "400 0.684914 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "500 0.683312 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "600 0.681339 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "700 0.678886 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "800 0.67581 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "900 0.67193 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "1000 0.667026 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "1100 0.660862 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "1200 0.653236 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "1300 0.644059 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "1400 0.63343 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "1500 0.621647 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "1600 0.609134 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "1700 0.596332 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "1800 0.583622 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "1900 0.571275 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "2000 0.559448 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "2100 0.548192 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "2200 0.537473 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "2300 0.527205 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "2400 0.517275 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "2500 0.507562 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "2600 0.497959 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "2700 0.488373 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "2800 0.478713 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "2900 0.468859 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "3000 0.458597 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "3100 0.447518 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "3200 0.434882 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "3300 0.419506 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "3400 0.399983 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "3500 0.375662 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "3600 0.347634 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "3700 0.318035 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "3800 0.288634 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "3900 0.260518 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "4000 0.234368 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "4100 0.210592 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "4200 0.189365 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "4300 0.170661 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "4400 0.154318 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "4500 0.140098 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "4600 0.127741 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "4700 0.116992 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "4800 0.107619 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "4900 0.0994168 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "5000 0.0922096 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "5100 0.0858491 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "5200 0.0802104 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "5300 0.0751892 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "5400 0.0706982 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "5500 0.0666641 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "5600 0.0630258 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "5700 0.0597316 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "5800 0.056738 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "5900 0.054008 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "6000 0.0515101 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "6100 0.0492175 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "6200 0.0471071 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "6300 0.045159 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "6400 0.043356 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "6500 0.0416831 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "6600 0.0401273 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "6700 0.0386772 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "6800 0.0373227 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "6900 0.0360551 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "7000 0.0348665 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "7100 0.03375 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "7200 0.0326994 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "7300 0.0317093 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "7400 0.0307747 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "7500 0.0298912 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "7600 0.0290549 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "7700 0.0282622 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "7800 0.0275098 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "7900 0.0267948 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "8000 0.0261146 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "8100 0.0254667 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "8200 0.024849 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "8300 0.0242595 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "8400 0.0236962 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "8500 0.0231576 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "8600 0.0226421 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "8700 0.0221482 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "8800 0.0216747 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "8900 0.0212203 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "9000 0.020784 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "9100 0.0203646 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "9200 0.0199613 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "9300 0.0195732 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "9400 0.0191994 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "9500 0.0188391 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "9600 0.0184918 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "9700 0.0181566 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "9800 0.017833 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "9900 0.0175204 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "10000 0.0172182 [[ 1.03044379]\n",
      " [ 1.46236861]]\n",
      "\n",
      "Hypothesis:  [[ 0.26805329]\n",
      " [ 0.25410715]\n",
      " [ 0.3181327 ]\n",
      " [ 0.28973016]] \n",
      "Correct:  [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-py3.5",
   "language": "python",
   "name": "tensorfllow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
